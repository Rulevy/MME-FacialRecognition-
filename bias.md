## Facial Recognition Bias

The most detrimental bias engraved in facial recognition technology is the in FBI’s use. It does not test for false positives or for racial bias. Black faces are detected less accurately and are disproportionately subject to police facial recognition due to the inherent bias that came from under representing in data training. A startup called Gfycat could not initially distinguish between Asians and people of darker complexion, simply because of the overwhelming majority of white people in their dataset. The technology in its nature, calls for categorization. Of course, labeling people can only backfire, in a society where not every person falls into six categories—two gender categories, and four racial. While the facial recognition technology is nearly perfect at distinguishing between a man and a woman, it is inherently sexist because the images that were used to train the technology, associate shopping and washing with women, and coaching and shooting with men. Also, after the Google Photos ape scandal, the technology has been mostly unresponsive to  gorillas, chimpanzees, or monkeys. The lack of data that represents people of color, highly threatens civil liberties (when implemented in the police force / FBI). It truly reiterates the grouping and stereotyping of black people. The simple solution is the widening of data sets to an equal number of demographics.
